{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "422b1c36-ec88-499e-bbd3-353dd0123241",
   "metadata": {},
   "source": [
    "## Some helpful code is provided bellow. It can serve to load data and organice functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9067fed3-8860-4d18-86ee-950fb10c2045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install yfinance\n",
    "import yfinance as yf\n",
    "precios = yf.Ticker('XLI').history(period=\"10y\", interval='1wk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "158bf6a1-1087-435d-b128-65e1266c11a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8268bed-d2ed-42eb-9262-abb2d9e39c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "precios = precios.Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e105698-53b8-4210-9606-964d2205a3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2014-04-07    42.180496\n",
       "2014-04-14    43.713589\n",
       "2014-04-21    43.514694\n",
       "2014-04-28    43.771591\n",
       "2014-05-05    43.929054\n",
       "2014-05-12    43.995335\n",
       "2014-05-19    44.376530\n",
       "2014-05-26    44.790882\n",
       "2014-06-02    45.835041\n",
       "2014-06-09    45.163799\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precios.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7e18e9b-d55a-4ac4-a629-606c335124c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "retornos = np.log(precios).diff()[1:].dropna()\n",
    "mat_retornos = retornos.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17d86641-9874-4264-9163-426c3ddfad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40b6194b-0e5d-4dee-8fa9-3f1947c9027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar(per = 20, umbral = 2):        \n",
    "        \n",
    "        # ventana de tiempo - Columnas\n",
    "        muestras = len(mat_retornos) - per\n",
    "\n",
    "        variables = np.zeros((1,per))\n",
    "        l = len(mat_retornos)\n",
    "\n",
    "        for x in range(muestras):\n",
    "            variables = np.concatenate((variables, mat_retornos[l-per-x: l-x].reshape((1,per))))\n",
    "\n",
    "        variables = variables[1:]\n",
    "\n",
    "        X = variables[:,:-1]*100\n",
    "        Y = variables[:,-1]*100\n",
    "        \n",
    "        neutral = [not x for x in ((Y>umbral)|(Y<-umbral))]\n",
    "        \n",
    "        Y[Y>umbral] = 2\n",
    "        Y[Y<-umbral] = 0\n",
    "        Y[neutral] = 1\n",
    "        \n",
    "        Y = OneHotEncoder(sparse=False).fit_transform(Y.reshape(-1,1))\n",
    "        #print(Y[5,:])\n",
    "        \n",
    "        i_entrenamiento = int(len(variables)*0.7) #la fila hasta donde va el entrenamiento y donde comienza el conjunto de prueba\n",
    "        \n",
    "        x_train = X[:i_entrenamiento, :]\n",
    "        x_test =  X[i_entrenamiento:, :]\n",
    "        y_train = Y[:i_entrenamiento]\n",
    "        y_test =  Y[i_entrenamiento:]\n",
    "        \n",
    "        return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e82a9eeb-dec6-47fe-831e-fdc10cbf3ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = preparar(per = 20, umbral = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "30a76edd-3dc9-49db-a1eb-3831e871605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b6385a5b-88ee-46a4-b536-739efefdffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo\n",
    "model = Sequential()\n",
    "\n",
    "capas = [5,3]\n",
    "\n",
    "# Agregar capa oculta\n",
    "model.add(Dense(capas[0], input_dim=x_train.shape[1], activation='sigmoid'))\n",
    "model.add(Dense(capas[1], input_dim=capas[0], activation='sigmoid'))\n",
    "#model.add(Dense(3, input_dim=3, activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1e5fefc5-b257-4ae9-b53e-9285432b0200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar capa de salida\n",
    "model.add(Dense(3, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fd17fa9b-92ba-4c28-a8db-b9a1321a65fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "11/11 [==============================] - 1s 4ms/step - loss: 0.2378 - accuracy: 0.2793\n",
      "Epoch 2/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2364 - accuracy: 0.2763\n",
      "Epoch 3/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2351 - accuracy: 0.2703\n",
      "Epoch 4/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2339 - accuracy: 0.2703\n",
      "Epoch 5/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2328 - accuracy: 0.2853\n",
      "Epoch 6/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2317 - accuracy: 0.2793\n",
      "Epoch 7/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2307 - accuracy: 0.3003\n",
      "Epoch 8/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2297 - accuracy: 0.2913\n",
      "Epoch 9/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2288 - accuracy: 0.3033\n",
      "Epoch 10/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2280 - accuracy: 0.3183\n",
      "Epoch 11/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2272 - accuracy: 0.3303\n",
      "Epoch 12/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2265 - accuracy: 0.3453\n",
      "Epoch 13/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2259 - accuracy: 0.3453\n",
      "Epoch 14/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2253 - accuracy: 0.3393\n",
      "Epoch 15/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2247 - accuracy: 0.3514\n",
      "Epoch 16/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2242 - accuracy: 0.3574\n",
      "Epoch 17/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2237 - accuracy: 0.3604\n",
      "Epoch 18/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2233 - accuracy: 0.3664\n",
      "Epoch 19/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2229 - accuracy: 0.3724\n",
      "Epoch 20/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.3814\n",
      "Epoch 21/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2221 - accuracy: 0.3784\n",
      "Epoch 22/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2218 - accuracy: 0.3814\n",
      "Epoch 23/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2215 - accuracy: 0.3934\n",
      "Epoch 24/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2212 - accuracy: 0.4024\n",
      "Epoch 25/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2209 - accuracy: 0.4024\n",
      "Epoch 26/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2206 - accuracy: 0.4024\n",
      "Epoch 27/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2204 - accuracy: 0.4054\n",
      "Epoch 28/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2201 - accuracy: 0.4084\n",
      "Epoch 29/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2200 - accuracy: 0.4054\n",
      "Epoch 30/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2197 - accuracy: 0.4144\n",
      "Epoch 31/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2196 - accuracy: 0.4144\n",
      "Epoch 32/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2194 - accuracy: 0.4174\n",
      "Epoch 33/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2192 - accuracy: 0.4234\n",
      "Epoch 34/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.4144\n",
      "Epoch 35/300\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.2189 - accuracy: 0.4174\n",
      "Epoch 36/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2188 - accuracy: 0.4114\n",
      "Epoch 37/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2187 - accuracy: 0.4114\n",
      "Epoch 38/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2185 - accuracy: 0.4144\n",
      "Epoch 39/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2184 - accuracy: 0.4144\n",
      "Epoch 40/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2182 - accuracy: 0.4144\n",
      "Epoch 41/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2181 - accuracy: 0.4204\n",
      "Epoch 42/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2180 - accuracy: 0.4144\n",
      "Epoch 43/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2179 - accuracy: 0.4234\n",
      "Epoch 44/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2178 - accuracy: 0.4204\n",
      "Epoch 45/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2177 - accuracy: 0.4204\n",
      "Epoch 46/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2176 - accuracy: 0.4204\n",
      "Epoch 47/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2175 - accuracy: 0.4144\n",
      "Epoch 48/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2174 - accuracy: 0.4204\n",
      "Epoch 49/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2173 - accuracy: 0.4204\n",
      "Epoch 50/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2172 - accuracy: 0.4234\n",
      "Epoch 51/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2171 - accuracy: 0.4294\n",
      "Epoch 52/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2170 - accuracy: 0.4264\n",
      "Epoch 53/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.4234\n",
      "Epoch 54/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2168 - accuracy: 0.4234\n",
      "Epoch 55/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2167 - accuracy: 0.4234\n",
      "Epoch 56/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2166 - accuracy: 0.4264\n",
      "Epoch 57/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2166 - accuracy: 0.4294\n",
      "Epoch 58/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2165 - accuracy: 0.4264\n",
      "Epoch 59/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2164 - accuracy: 0.4264\n",
      "Epoch 60/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2163 - accuracy: 0.4264\n",
      "Epoch 61/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2162 - accuracy: 0.4294\n",
      "Epoch 62/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2161 - accuracy: 0.4294\n",
      "Epoch 63/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2160 - accuracy: 0.4264\n",
      "Epoch 64/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2160 - accuracy: 0.4264\n",
      "Epoch 65/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2159 - accuracy: 0.4264\n",
      "Epoch 66/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2158 - accuracy: 0.4264\n",
      "Epoch 67/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2157 - accuracy: 0.4324\n",
      "Epoch 68/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2156 - accuracy: 0.4324\n",
      "Epoch 69/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2155 - accuracy: 0.4324\n",
      "Epoch 70/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2154 - accuracy: 0.4324\n",
      "Epoch 71/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.4294\n",
      "Epoch 72/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2153 - accuracy: 0.4354\n",
      "Epoch 73/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2152 - accuracy: 0.4354\n",
      "Epoch 74/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2151 - accuracy: 0.4354\n",
      "Epoch 75/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2150 - accuracy: 0.4384\n",
      "Epoch 76/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2149 - accuracy: 0.4354\n",
      "Epoch 77/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2148 - accuracy: 0.4384\n",
      "Epoch 78/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2147 - accuracy: 0.4354\n",
      "Epoch 79/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2146 - accuracy: 0.4354\n",
      "Epoch 80/300\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2145 - accuracy: 0.4354\n",
      "Epoch 81/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2144 - accuracy: 0.4444\n",
      "Epoch 82/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2143 - accuracy: 0.4414\n",
      "Epoch 83/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2142 - accuracy: 0.4384\n",
      "Epoch 84/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2141 - accuracy: 0.4384\n",
      "Epoch 85/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2140 - accuracy: 0.4384\n",
      "Epoch 86/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2139 - accuracy: 0.4384\n",
      "Epoch 87/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2137 - accuracy: 0.4384\n",
      "Epoch 88/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2136 - accuracy: 0.4384\n",
      "Epoch 89/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2135 - accuracy: 0.4384\n",
      "Epoch 90/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2134 - accuracy: 0.4444\n",
      "Epoch 91/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2133 - accuracy: 0.4444\n",
      "Epoch 92/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2132 - accuracy: 0.4474\n",
      "Epoch 93/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2131 - accuracy: 0.4474\n",
      "Epoch 94/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2130 - accuracy: 0.4474\n",
      "Epoch 95/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2129 - accuracy: 0.4535\n",
      "Epoch 96/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2128 - accuracy: 0.4505\n",
      "Epoch 97/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2127 - accuracy: 0.4595\n",
      "Epoch 98/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2125 - accuracy: 0.4535\n",
      "Epoch 99/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2125 - accuracy: 0.4474\n",
      "Epoch 100/300\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2123 - accuracy: 0.4474\n",
      "Epoch 101/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2122 - accuracy: 0.4535\n",
      "Epoch 102/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2121 - accuracy: 0.4595\n",
      "Epoch 103/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2119 - accuracy: 0.4625\n",
      "Epoch 104/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2118 - accuracy: 0.4625\n",
      "Epoch 105/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2117 - accuracy: 0.4625\n",
      "Epoch 106/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2116 - accuracy: 0.4655\n",
      "Epoch 107/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2114 - accuracy: 0.4655\n",
      "Epoch 108/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2114 - accuracy: 0.4595\n",
      "Epoch 109/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2112 - accuracy: 0.4595\n",
      "Epoch 110/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2111 - accuracy: 0.4685\n",
      "Epoch 111/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2109 - accuracy: 0.4715\n",
      "Epoch 112/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2108 - accuracy: 0.4775\n",
      "Epoch 113/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2107 - accuracy: 0.4805\n",
      "Epoch 114/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2105 - accuracy: 0.4835\n",
      "Epoch 115/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2104 - accuracy: 0.4775\n",
      "Epoch 116/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.4805\n",
      "Epoch 117/300\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.2102 - accuracy: 0.4805\n",
      "Epoch 118/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.4805\n",
      "Epoch 119/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2099 - accuracy: 0.4835\n",
      "Epoch 120/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2098 - accuracy: 0.4805\n",
      "Epoch 121/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2096 - accuracy: 0.4775\n",
      "Epoch 122/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2095 - accuracy: 0.4835\n",
      "Epoch 123/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2093 - accuracy: 0.4865\n",
      "Epoch 124/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.4835\n",
      "Epoch 125/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.4895\n",
      "Epoch 126/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2089 - accuracy: 0.4925\n",
      "Epoch 127/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.4925\n",
      "Epoch 128/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.4925\n",
      "Epoch 129/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2085 - accuracy: 0.4925\n",
      "Epoch 130/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2084 - accuracy: 0.4985\n",
      "Epoch 131/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.4985\n",
      "Epoch 132/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.4985\n",
      "Epoch 133/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.4985\n",
      "Epoch 134/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2079 - accuracy: 0.5045\n",
      "Epoch 135/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2078 - accuracy: 0.5045\n",
      "Epoch 136/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 0.5075\n",
      "Epoch 137/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2075 - accuracy: 0.5105\n",
      "Epoch 138/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2074 - accuracy: 0.5105\n",
      "Epoch 139/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2073 - accuracy: 0.5105\n",
      "Epoch 140/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2071 - accuracy: 0.5135\n",
      "Epoch 141/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2070 - accuracy: 0.5135\n",
      "Epoch 142/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2069 - accuracy: 0.5135\n",
      "Epoch 143/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2068 - accuracy: 0.5135\n",
      "Epoch 144/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2067 - accuracy: 0.5165\n",
      "Epoch 145/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2065 - accuracy: 0.5165\n",
      "Epoch 146/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2064 - accuracy: 0.5165\n",
      "Epoch 147/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2063 - accuracy: 0.5195\n",
      "Epoch 148/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2062 - accuracy: 0.5165\n",
      "Epoch 149/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2061 - accuracy: 0.5165\n",
      "Epoch 150/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2059 - accuracy: 0.5165\n",
      "Epoch 151/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2058 - accuracy: 0.5195\n",
      "Epoch 152/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2057 - accuracy: 0.5195\n",
      "Epoch 153/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2056 - accuracy: 0.5225\n",
      "Epoch 154/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2055 - accuracy: 0.5225\n",
      "Epoch 155/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2053 - accuracy: 0.5225\n",
      "Epoch 156/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2052 - accuracy: 0.5255\n",
      "Epoch 157/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2051 - accuracy: 0.5225\n",
      "Epoch 158/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2050 - accuracy: 0.5225\n",
      "Epoch 159/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2049 - accuracy: 0.5225\n",
      "Epoch 160/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2048 - accuracy: 0.5285\n",
      "Epoch 161/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2047 - accuracy: 0.5285\n",
      "Epoch 162/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2045 - accuracy: 0.5285\n",
      "Epoch 163/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2044 - accuracy: 0.5285\n",
      "Epoch 164/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2043 - accuracy: 0.5285\n",
      "Epoch 165/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2042 - accuracy: 0.5255\n",
      "Epoch 166/300\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.2041 - accuracy: 0.5285\n",
      "Epoch 167/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2040 - accuracy: 0.5285\n",
      "Epoch 168/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2039 - accuracy: 0.5285\n",
      "Epoch 169/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2038 - accuracy: 0.5285\n",
      "Epoch 170/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2037 - accuracy: 0.5315\n",
      "Epoch 171/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2035 - accuracy: 0.5285\n",
      "Epoch 172/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.5285\n",
      "Epoch 173/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2033 - accuracy: 0.5285\n",
      "Epoch 174/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2032 - accuracy: 0.5345\n",
      "Epoch 175/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2031 - accuracy: 0.5345\n",
      "Epoch 176/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 0.5345\n",
      "Epoch 177/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2029 - accuracy: 0.5375\n",
      "Epoch 178/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2028 - accuracy: 0.5435\n",
      "Epoch 179/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2027 - accuracy: 0.5435\n",
      "Epoch 180/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2026 - accuracy: 0.5435\n",
      "Epoch 181/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2025 - accuracy: 0.5435\n",
      "Epoch 182/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2024 - accuracy: 0.5435\n",
      "Epoch 183/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2023 - accuracy: 0.5405\n",
      "Epoch 184/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2022 - accuracy: 0.5435\n",
      "Epoch 185/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2021 - accuracy: 0.5435\n",
      "Epoch 186/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2020 - accuracy: 0.5435\n",
      "Epoch 187/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2019 - accuracy: 0.5465\n",
      "Epoch 188/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2018 - accuracy: 0.5435\n",
      "Epoch 189/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2017 - accuracy: 0.5435\n",
      "Epoch 190/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2016 - accuracy: 0.5495\n",
      "Epoch 191/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2015 - accuracy: 0.5435\n",
      "Epoch 192/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2013 - accuracy: 0.5465\n",
      "Epoch 193/300\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2012 - accuracy: 0.5465\n",
      "Epoch 194/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2011 - accuracy: 0.5465\n",
      "Epoch 195/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2010 - accuracy: 0.5465\n",
      "Epoch 196/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2009 - accuracy: 0.5465\n",
      "Epoch 197/300\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2008 - accuracy: 0.5465\n",
      "Epoch 198/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2007 - accuracy: 0.5465\n",
      "Epoch 199/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2007 - accuracy: 0.5465\n",
      "Epoch 200/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2005 - accuracy: 0.5435\n",
      "Epoch 201/300\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2004 - accuracy: 0.5435\n",
      "Epoch 202/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2003 - accuracy: 0.5435\n",
      "Epoch 203/300\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2002 - accuracy: 0.5465\n",
      "Epoch 204/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2002 - accuracy: 0.5465\n",
      "Epoch 205/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2001 - accuracy: 0.5435\n",
      "Epoch 206/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2000 - accuracy: 0.5495\n",
      "Epoch 207/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.5495\n",
      "Epoch 208/300\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1998 - accuracy: 0.5495\n",
      "Epoch 209/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1997 - accuracy: 0.5495\n",
      "Epoch 210/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1996 - accuracy: 0.5495\n",
      "Epoch 211/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1995 - accuracy: 0.5495\n",
      "Epoch 212/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1994 - accuracy: 0.5495\n",
      "Epoch 213/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1993 - accuracy: 0.5495\n",
      "Epoch 214/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1992 - accuracy: 0.5495\n",
      "Epoch 215/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1991 - accuracy: 0.5526\n",
      "Epoch 216/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1990 - accuracy: 0.5526\n",
      "Epoch 217/300\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1989 - accuracy: 0.5526\n",
      "Epoch 218/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1988 - accuracy: 0.5526\n",
      "Epoch 219/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1987 - accuracy: 0.5526\n",
      "Epoch 220/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1987 - accuracy: 0.5556\n",
      "Epoch 221/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1986 - accuracy: 0.5556\n",
      "Epoch 222/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1985 - accuracy: 0.5556\n",
      "Epoch 223/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1984 - accuracy: 0.5556\n",
      "Epoch 224/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1983 - accuracy: 0.5556\n",
      "Epoch 225/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.5556\n",
      "Epoch 226/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1981 - accuracy: 0.5556\n",
      "Epoch 227/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1980 - accuracy: 0.5586\n",
      "Epoch 228/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1979 - accuracy: 0.5586\n",
      "Epoch 229/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1978 - accuracy: 0.5646\n",
      "Epoch 230/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1977 - accuracy: 0.5616\n",
      "Epoch 231/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 0.5616\n",
      "Epoch 232/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1976 - accuracy: 0.5646\n",
      "Epoch 233/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1975 - accuracy: 0.5646\n",
      "Epoch 234/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1974 - accuracy: 0.5646\n",
      "Epoch 235/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1973 - accuracy: 0.5646\n",
      "Epoch 236/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1972 - accuracy: 0.5646\n",
      "Epoch 237/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1971 - accuracy: 0.5646\n",
      "Epoch 238/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1971 - accuracy: 0.5646\n",
      "Epoch 239/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1969 - accuracy: 0.5676\n",
      "Epoch 240/300\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1969 - accuracy: 0.5646\n",
      "Epoch 241/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1968 - accuracy: 0.5646\n",
      "Epoch 242/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.5676\n",
      "Epoch 243/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1966 - accuracy: 0.5646\n",
      "Epoch 244/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1965 - accuracy: 0.5646\n",
      "Epoch 245/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.5676\n",
      "Epoch 246/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 0.5676\n",
      "Epoch 247/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1962 - accuracy: 0.5676\n",
      "Epoch 248/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1961 - accuracy: 0.5706\n",
      "Epoch 249/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1961 - accuracy: 0.5706\n",
      "Epoch 250/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1960 - accuracy: 0.5676\n",
      "Epoch 251/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1959 - accuracy: 0.5676\n",
      "Epoch 252/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.5676\n",
      "Epoch 253/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1957 - accuracy: 0.5676\n",
      "Epoch 254/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.5646\n",
      "Epoch 255/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.5706\n",
      "Epoch 256/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.5676\n",
      "Epoch 257/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1954 - accuracy: 0.5706\n",
      "Epoch 258/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1953 - accuracy: 0.5736\n",
      "Epoch 259/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1952 - accuracy: 0.5736\n",
      "Epoch 260/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1951 - accuracy: 0.5736\n",
      "Epoch 261/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1951 - accuracy: 0.5766\n",
      "Epoch 262/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1950 - accuracy: 0.5736\n",
      "Epoch 263/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1949 - accuracy: 0.5706\n",
      "Epoch 264/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1948 - accuracy: 0.5706\n",
      "Epoch 265/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1948 - accuracy: 0.5766\n",
      "Epoch 266/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1947 - accuracy: 0.5736\n",
      "Epoch 267/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1946 - accuracy: 0.5736\n",
      "Epoch 268/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1945 - accuracy: 0.5736\n",
      "Epoch 269/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1945 - accuracy: 0.5736\n",
      "Epoch 270/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1944 - accuracy: 0.5736\n",
      "Epoch 271/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1943 - accuracy: 0.5736\n",
      "Epoch 272/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1942 - accuracy: 0.5736\n",
      "Epoch 273/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1941 - accuracy: 0.5736\n",
      "Epoch 274/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1941 - accuracy: 0.5736\n",
      "Epoch 275/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1940 - accuracy: 0.5736\n",
      "Epoch 276/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1939 - accuracy: 0.5766\n",
      "Epoch 277/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1938 - accuracy: 0.5766\n",
      "Epoch 278/300\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.1938 - accuracy: 0.5766\n",
      "Epoch 279/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1937 - accuracy: 0.5766\n",
      "Epoch 280/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.5766\n",
      "Epoch 281/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1936 - accuracy: 0.5766\n",
      "Epoch 282/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1935 - accuracy: 0.5766\n",
      "Epoch 283/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1934 - accuracy: 0.5766\n",
      "Epoch 284/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1934 - accuracy: 0.5766\n",
      "Epoch 285/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1933 - accuracy: 0.5766\n",
      "Epoch 286/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1932 - accuracy: 0.5766\n",
      "Epoch 287/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.5766\n",
      "Epoch 288/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.5736\n",
      "Epoch 289/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1930 - accuracy: 0.5766\n",
      "Epoch 290/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1929 - accuracy: 0.5766\n",
      "Epoch 291/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1928 - accuracy: 0.5766\n",
      "Epoch 292/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1927 - accuracy: 0.5766\n",
      "Epoch 293/300\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1927 - accuracy: 0.5766\n",
      "Epoch 294/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1926 - accuracy: 0.5766\n",
      "Epoch 295/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.5766\n",
      "Epoch 296/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1924 - accuracy: 0.5766\n",
      "Epoch 297/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 0.5766\n",
      "Epoch 298/300\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1922 - accuracy: 0.5766\n",
      "Epoch 299/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1921 - accuracy: 0.5766\n",
      "Epoch 300/300\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1921 - accuracy: 0.5766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x12a40182ac0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compilar el modelo\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(x_train, y_train, epochs=300, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0a369fb2-e924-48ce-9f31-83c222d07296",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.5766\n",
      "Loss: 0.1918998658657074, Accuracy: 0.5765765905380249\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "Predicción final:\n",
      "[0.57114226 0.50012046 0.5162743  0.5311422  0.6022969  0.55017465\n",
      " 0.50578874 0.5892636  0.67357624 0.5058648  0.54184544 0.66810864\n",
      " 0.5735344  0.5684922  0.5649032  0.507909   0.50965154 0.51057\n",
      " 0.57576096 0.6100852  0.51008534 0.52958685 0.5420181  0.53895456\n",
      " 0.55085206 0.72274554 0.57674706 0.6544927  0.5715285  0.6833667\n",
      " 0.56722724 0.71544856 0.6576423  0.6984029  0.5365919  0.66935235\n",
      " 0.5507248  0.649928   0.62208074 0.50644743 0.6060325  0.64308\n",
      " 0.50225484 0.5913062  0.55533594 0.50800467 0.5127758  0.6794161\n",
      " 0.52106845 0.70329666 0.5186444  0.5089973  0.53945374 0.54944366\n",
      " 0.6545456  0.568243  ]\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "loss, accuracy = model.evaluate(x_train, y_train)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')\n",
    "\n",
    "# Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "636cc035-98ef-462d-a6fd-00c48920a73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.26233405, 0.4949322 , 0.24026917],\n",
       "       [0.2538181 , 0.5322305 , 0.21880971],\n",
       "       [0.24578457, 0.5247973 , 0.23137477],\n",
       "       [0.35473496, 0.3172512 , 0.31421676],\n",
       "       [0.23530468, 0.40543026, 0.338673  ],\n",
       "       [0.3234763 , 0.40662292, 0.25145343],\n",
       "       [0.24477331, 0.49905732, 0.2515346 ],\n",
       "       [0.22671783, 0.21785368, 0.57683045],\n",
       "       [0.28365672, 0.46441862, 0.24166968],\n",
       "       [0.2325883 , 0.16175103, 0.6668088 ],\n",
       "       [0.34419543, 0.4426557 , 0.23909701],\n",
       "       [0.24781989, 0.47783756, 0.2683112 ],\n",
       "       [0.24340066, 0.5240025 , 0.23442261],\n",
       "       [0.23322074, 0.41979074, 0.33708254],\n",
       "       [0.34285972, 0.4758432 , 0.21466418],\n",
       "       [0.22567624, 0.4754726 , 0.289575  ],\n",
       "       [0.27618578, 0.52961123, 0.20157604],\n",
       "       [0.28747144, 0.47509465, 0.2197802 ],\n",
       "       [0.23624837, 0.5382514 , 0.23191318],\n",
       "       [0.28318822, 0.2450733 , 0.47447556],\n",
       "       [0.32206753, 0.48276305, 0.22758032],\n",
       "       [0.27026606, 0.2222095 , 0.53149   ],\n",
       "       [0.22680172, 0.47639105, 0.2965504 ],\n",
       "       [0.3695198 , 0.1531249 , 0.55667347],\n",
       "       [0.27775732, 0.12279028, 0.70968634],\n",
       "       [0.31787476, 0.18945083, 0.5586302 ],\n",
       "       [0.36099324, 0.18073441, 0.5249622 ],\n",
       "       [0.27118182, 0.47891384, 0.24295211],\n",
       "       [0.25769332, 0.14540637, 0.6460892 ],\n",
       "       [0.30455905, 0.32713127, 0.33471853],\n",
       "       [0.35968125, 0.16520132, 0.5602267 ],\n",
       "       [0.22672261, 0.35785538, 0.39128655],\n",
       "       [0.32806143, 0.1870595 , 0.54802114],\n",
       "       [0.32572824, 0.4479988 , 0.208293  ],\n",
       "       [0.23866217, 0.313702  , 0.44436187],\n",
       "       [0.32538682, 0.2727843 , 0.39975783],\n",
       "       [0.26068956, 0.5086388 , 0.22891694],\n",
       "       [0.27953357, 0.47699654, 0.26178628],\n",
       "       [0.22811864, 0.48301178, 0.28134957],\n",
       "       [0.34913236, 0.19651407, 0.489355  ],\n",
       "       [0.22761162, 0.3620081 , 0.38947678],\n",
       "       [0.2846525 , 0.37577087, 0.37470046],\n",
       "       [0.22318015, 0.4461324 , 0.31487167],\n",
       "       [0.24355927, 0.16846992, 0.65979725],\n",
       "       [0.3845321 , 0.44653913, 0.1760436 ],\n",
       "       [0.23952122, 0.41479626, 0.3334189 ],\n",
       "       [0.29583058, 0.14353141, 0.6328572 ],\n",
       "       [0.2960335 , 0.21484177, 0.4796658 ],\n",
       "       [0.34420007, 0.40922293, 0.2633692 ],\n",
       "       [0.2274275 , 0.34195802, 0.41056636],\n",
       "       [0.28986427, 0.30922344, 0.3628579 ],\n",
       "       [0.25746325, 0.12805474, 0.7180808 ],\n",
       "       [0.32529902, 0.483091  , 0.22954483],\n",
       "       [0.23791845, 0.16533737, 0.6133936 ],\n",
       "       [0.33544227, 0.20222887, 0.49865833],\n",
       "       [0.41300455, 0.34906453, 0.2556538 ],\n",
       "       [0.2376688 , 0.48684525, 0.26828533],\n",
       "       [0.30818266, 0.1621919 , 0.5884972 ],\n",
       "       [0.32697302, 0.3898955 , 0.24209516],\n",
       "       [0.274724  , 0.45988706, 0.25784144],\n",
       "       [0.33040246, 0.4635204 , 0.19259927],\n",
       "       [0.25021544, 0.36990502, 0.3610864 ],\n",
       "       [0.23497029, 0.14547586, 0.6661281 ],\n",
       "       [0.24960038, 0.27653593, 0.498582  ],\n",
       "       [0.28366953, 0.17192768, 0.6194258 ],\n",
       "       [0.23878182, 0.19054493, 0.61923254],\n",
       "       [0.30375618, 0.4654616 , 0.26440248],\n",
       "       [0.23297325, 0.47477302, 0.28235084],\n",
       "       [0.34340227, 0.40528095, 0.26907107],\n",
       "       [0.25053144, 0.5411101 , 0.2146208 ],\n",
       "       [0.29826137, 0.52863145, 0.17821261],\n",
       "       [0.25142133, 0.2606829 , 0.44929558],\n",
       "       [0.23147124, 0.4686444 , 0.29814374],\n",
       "       [0.29596382, 0.3625152 , 0.322221  ],\n",
       "       [0.22468594, 0.46124935, 0.31019905],\n",
       "       [0.23585066, 0.1562886 , 0.67700434],\n",
       "       [0.30235222, 0.15920462, 0.6275524 ],\n",
       "       [0.26584724, 0.4236761 , 0.32866162],\n",
       "       [0.28385645, 0.11388747, 0.74340147],\n",
       "       [0.3825649 , 0.18974398, 0.4682465 ],\n",
       "       [0.3363239 , 0.13819076, 0.6214644 ],\n",
       "       [0.28435278, 0.53740704, 0.18012026],\n",
       "       [0.3187286 , 0.15629669, 0.5905917 ],\n",
       "       [0.42142987, 0.36624107, 0.23656058],\n",
       "       [0.22845075, 0.3314715 , 0.4088003 ],\n",
       "       [0.21685559, 0.36135793, 0.39851868],\n",
       "       [0.2528007 , 0.2981261 , 0.480302  ],\n",
       "       [0.24392457, 0.51435953, 0.25184166],\n",
       "       [0.23296292, 0.20938903, 0.55580693],\n",
       "       [0.37550744, 0.17355393, 0.5103336 ],\n",
       "       [0.35161906, 0.30348107, 0.34332195],\n",
       "       [0.27859867, 0.5061427 , 0.21259242],\n",
       "       [0.31893077, 0.11707547, 0.70332646],\n",
       "       [0.38265526, 0.20264909, 0.44767788],\n",
       "       [0.2654408 , 0.20419139, 0.5857389 ],\n",
       "       [0.22431807, 0.44824463, 0.3211076 ],\n",
       "       [0.34808928, 0.13224645, 0.6425502 ],\n",
       "       [0.30523098, 0.16198866, 0.6073603 ],\n",
       "       [0.25294006, 0.13482648, 0.7118178 ],\n",
       "       [0.3945014 , 0.21845126, 0.41463262],\n",
       "       [0.32692063, 0.46244952, 0.19792646],\n",
       "       [0.24363975, 0.49255443, 0.25796375],\n",
       "       [0.29082963, 0.36671022, 0.30708298],\n",
       "       [0.31960613, 0.5091376 , 0.17793274],\n",
       "       [0.24083504, 0.31485093, 0.44945812],\n",
       "       [0.26337653, 0.5144072 , 0.2264579 ],\n",
       "       [0.29045847, 0.11508424, 0.73327553],\n",
       "       [0.26241642, 0.23649345, 0.54540473],\n",
       "       [0.2757658 , 0.22424969, 0.5477101 ],\n",
       "       [0.26561826, 0.14607476, 0.6411025 ],\n",
       "       [0.3613502 , 0.21282555, 0.4768581 ],\n",
       "       [0.3488459 , 0.37626508, 0.26185152],\n",
       "       [0.31040603, 0.3902054 , 0.25989762],\n",
       "       [0.34961045, 0.15329431, 0.5669931 ],\n",
       "       [0.24625722, 0.19502401, 0.5593973 ],\n",
       "       [0.25719872, 0.3097027 , 0.4650277 ],\n",
       "       [0.24968833, 0.41638356, 0.33608696],\n",
       "       [0.28758332, 0.16748185, 0.62168777],\n",
       "       [0.25803703, 0.20316124, 0.58287275],\n",
       "       [0.28905454, 0.49375612, 0.23924777],\n",
       "       [0.29880887, 0.43141863, 0.24100427],\n",
       "       [0.3044447 , 0.1406408 , 0.6389124 ],\n",
       "       [0.3927411 , 0.43281245, 0.1849664 ],\n",
       "       [0.22287346, 0.39336345, 0.36343953],\n",
       "       [0.2584894 , 0.40265438, 0.32225236],\n",
       "       [0.3281204 , 0.3159507 , 0.35228875],\n",
       "       [0.23784278, 0.41082677, 0.3383474 ],\n",
       "       [0.21563685, 0.30748716, 0.45966196],\n",
       "       [0.36259156, 0.24633315, 0.43341416],\n",
       "       [0.27775124, 0.20515488, 0.53778255],\n",
       "       [0.35044998, 0.21722   , 0.48901352],\n",
       "       [0.30826393, 0.2871046 , 0.36504954],\n",
       "       [0.3267219 , 0.219954  , 0.48264703],\n",
       "       [0.27671653, 0.42473993, 0.26876295],\n",
       "       [0.28226677, 0.51436144, 0.21796808],\n",
       "       [0.36094975, 0.26719016, 0.37830973],\n",
       "       [0.24915953, 0.3828404 , 0.33815095],\n",
       "       [0.3610736 , 0.22171552, 0.4310462 ],\n",
       "       [0.29018435, 0.39026508, 0.3204619 ],\n",
       "       [0.30103076, 0.42784786, 0.2581645 ],\n",
       "       [0.2441631 , 0.21789752, 0.5212737 ],\n",
       "       [0.40506366, 0.319949  , 0.29519314],\n",
       "       [0.29888177, 0.5147195 , 0.18803355],\n",
       "       [0.24317971, 0.43747953, 0.30936596],\n",
       "       [0.36380416, 0.21647747, 0.4266419 ],\n",
       "       [0.35029656, 0.2424832 , 0.4209883 ],\n",
       "       [0.34057677, 0.416842  , 0.23143883],\n",
       "       [0.24902984, 0.5018185 , 0.2452153 ],\n",
       "       [0.31529164, 0.24040228, 0.42575714],\n",
       "       [0.22702122, 0.4737921 , 0.28975374],\n",
       "       [0.26425752, 0.41057393, 0.34682786],\n",
       "       [0.24861412, 0.5271144 , 0.22820745],\n",
       "       [0.25527978, 0.50024134, 0.24139473],\n",
       "       [0.23864867, 0.51474446, 0.24546883],\n",
       "       [0.29376283, 0.5321398 , 0.18222758],\n",
       "       [0.23584236, 0.52635926, 0.24145341],\n",
       "       [0.23064779, 0.42282513, 0.32853454],\n",
       "       [0.32211685, 0.26367214, 0.42702365],\n",
       "       [0.23609339, 0.5352794 , 0.23560794],\n",
       "       [0.34427762, 0.49573562, 0.15858334],\n",
       "       [0.21230419, 0.2748506 , 0.49568692],\n",
       "       [0.40170822, 0.34416544, 0.2733442 ],\n",
       "       [0.26182842, 0.4954377 , 0.2420533 ],\n",
       "       [0.24471852, 0.16268845, 0.6687602 ],\n",
       "       [0.3858795 , 0.19057283, 0.46242788],\n",
       "       [0.23158233, 0.43668228, 0.3177269 ],\n",
       "       [0.24894862, 0.484436  , 0.25656125],\n",
       "       [0.31978872, 0.48370638, 0.23259184],\n",
       "       [0.24581665, 0.27587298, 0.49047446],\n",
       "       [0.36514774, 0.22437909, 0.41789714],\n",
       "       [0.27490926, 0.48529947, 0.22875096],\n",
       "       [0.2399557 , 0.52379507, 0.24297294],\n",
       "       [0.2603015 , 0.5386624 , 0.20450433],\n",
       "       [0.21829742, 0.38767782, 0.3714702 ],\n",
       "       [0.31891182, 0.49089074, 0.22421268],\n",
       "       [0.27398816, 0.5084149 , 0.2233152 ],\n",
       "       [0.22265281, 0.44241753, 0.31857905],\n",
       "       [0.36744246, 0.14234892, 0.5952753 ],\n",
       "       [0.2526366 , 0.5044299 , 0.23916091],\n",
       "       [0.2315019 , 0.4070353 , 0.35913268],\n",
       "       [0.24993826, 0.3092353 , 0.4531004 ],\n",
       "       [0.3197536 , 0.20518813, 0.5153687 ],\n",
       "       [0.26364478, 0.20568302, 0.5655349 ],\n",
       "       [0.29813546, 0.29358998, 0.38275242],\n",
       "       [0.260893  , 0.5121578 , 0.22496128],\n",
       "       [0.2452206 , 0.47416714, 0.2802234 ],\n",
       "       [0.330675  , 0.48123044, 0.17733963],\n",
       "       [0.27908897, 0.2062353 , 0.58326304],\n",
       "       [0.2505641 , 0.22302145, 0.55761474],\n",
       "       [0.226916  , 0.2419262 , 0.52067155],\n",
       "       [0.24473763, 0.24033949, 0.5398137 ],\n",
       "       [0.30418956, 0.38509148, 0.28309447],\n",
       "       [0.2608741 , 0.5121255 , 0.22500704],\n",
       "       [0.24311401, 0.14935465, 0.6925879 ],\n",
       "       [0.41850746, 0.38291892, 0.22125039],\n",
       "       [0.22886659, 0.16556655, 0.658815  ],\n",
       "       [0.32093355, 0.25675595, 0.43398988],\n",
       "       [0.26564792, 0.47218412, 0.25243214],\n",
       "       [0.23374197, 0.54147   , 0.23155853],\n",
       "       [0.24752368, 0.39487112, 0.3693574 ],\n",
       "       [0.3533947 , 0.4896358 , 0.1553209 ],\n",
       "       [0.23187248, 0.15226232, 0.64266247],\n",
       "       [0.4131815 , 0.30885735, 0.30250603],\n",
       "       [0.23548107, 0.1749729 , 0.60194916],\n",
       "       [0.25534025, 0.14104643, 0.69393724],\n",
       "       [0.25151625, 0.26315144, 0.4667868 ],\n",
       "       [0.2996263 , 0.39739004, 0.34349075],\n",
       "       [0.29885352, 0.14615324, 0.654025  ],\n",
       "       [0.2640975 , 0.28197956, 0.44104576],\n",
       "       [0.35576695, 0.12164885, 0.6592756 ],\n",
       "       [0.3547738 , 0.12102667, 0.6623199 ],\n",
       "       [0.3822375 , 0.1881493 , 0.46828026],\n",
       "       [0.38236392, 0.18169785, 0.48111436],\n",
       "       [0.3129434 , 0.3566489 , 0.32416895],\n",
       "       [0.2954409 , 0.4495752 , 0.24257447],\n",
       "       [0.24253662, 0.43300566, 0.3142427 ],\n",
       "       [0.33296454, 0.15188152, 0.58482873],\n",
       "       [0.30006424, 0.17454188, 0.5718607 ],\n",
       "       [0.24892563, 0.2515782 , 0.52258646],\n",
       "       [0.281307  , 0.31054848, 0.38871205],\n",
       "       [0.26202026, 0.5160102 , 0.22126241],\n",
       "       [0.22698788, 0.30342823, 0.44895363],\n",
       "       [0.31942075, 0.5100433 , 0.17419943],\n",
       "       [0.2938613 , 0.3200245 , 0.39843914],\n",
       "       [0.28472677, 0.24113055, 0.46876904],\n",
       "       [0.25505638, 0.44117686, 0.29469335],\n",
       "       [0.23304695, 0.50932235, 0.2602672 ],\n",
       "       [0.24295254, 0.52112716, 0.24551165],\n",
       "       [0.23759551, 0.47000718, 0.28945726],\n",
       "       [0.24919108, 0.39877602, 0.3465695 ],\n",
       "       [0.39201918, 0.24350944, 0.40337542],\n",
       "       [0.2594879 , 0.49900267, 0.23560162],\n",
       "       [0.3208248 , 0.12431249, 0.6746504 ],\n",
       "       [0.276758  , 0.4164952 , 0.2729108 ],\n",
       "       [0.24359006, 0.18469015, 0.63515425],\n",
       "       [0.2951838 , 0.21009508, 0.53989094],\n",
       "       [0.24562041, 0.21715158, 0.57400465],\n",
       "       [0.3100984 , 0.15611476, 0.59995914],\n",
       "       [0.28889725, 0.30698773, 0.3976345 ],\n",
       "       [0.38595095, 0.24326329, 0.38229337],\n",
       "       [0.3027518 , 0.3377061 , 0.31066462],\n",
       "       [0.32001215, 0.4607155 , 0.203756  ],\n",
       "       [0.24201542, 0.2317291 , 0.50342566],\n",
       "       [0.33324438, 0.43210632, 0.25569808],\n",
       "       [0.25773403, 0.1591166 , 0.62175006],\n",
       "       [0.268659  , 0.31816033, 0.43227434],\n",
       "       [0.2734656 , 0.17476617, 0.6058943 ],\n",
       "       [0.23950246, 0.47329584, 0.28709063],\n",
       "       [0.369916  , 0.2205534 , 0.4318123 ],\n",
       "       [0.37430885, 0.17854454, 0.4944726 ],\n",
       "       [0.37801373, 0.19943097, 0.4486082 ],\n",
       "       [0.28772184, 0.21663238, 0.48053667],\n",
       "       [0.25609145, 0.5087729 , 0.23250769],\n",
       "       [0.25478676, 0.332721  , 0.38588056],\n",
       "       [0.2309156 , 0.33363715, 0.42400485],\n",
       "       [0.29120716, 0.15537226, 0.6443147 ],\n",
       "       [0.26353493, 0.51840407, 0.22582139],\n",
       "       [0.2203681 , 0.20031644, 0.59961843],\n",
       "       [0.31067315, 0.5207637 , 0.16858754],\n",
       "       [0.29114723, 0.47230807, 0.23229995],\n",
       "       [0.22771274, 0.4961712 , 0.2718613 ],\n",
       "       [0.3182282 , 0.4219156 , 0.24211764],\n",
       "       [0.23420833, 0.5265324 , 0.24240848],\n",
       "       [0.25346994, 0.26333848, 0.52359176],\n",
       "       [0.30469498, 0.30766279, 0.38911963],\n",
       "       [0.22080854, 0.18679523, 0.6169434 ],\n",
       "       [0.28122163, 0.45552573, 0.28686208],\n",
       "       [0.25713757, 0.52212137, 0.23129676],\n",
       "       [0.39878023, 0.39426643, 0.22896211],\n",
       "       [0.35455617, 0.12114828, 0.6619823 ],\n",
       "       [0.3785919 , 0.19824302, 0.4503441 ],\n",
       "       [0.28381065, 0.11415424, 0.74165046],\n",
       "       [0.31534615, 0.3593813 , 0.3110965 ],\n",
       "       [0.26956803, 0.11802297, 0.7286765 ],\n",
       "       [0.35055828, 0.28119382, 0.38275954],\n",
       "       [0.25290644, 0.37056142, 0.35630184],\n",
       "       [0.28586927, 0.29218814, 0.45040908],\n",
       "       [0.3568268 , 0.1293562 , 0.6316269 ],\n",
       "       [0.36888045, 0.21816169, 0.42091107],\n",
       "       [0.3001056 , 0.14179035, 0.6322248 ],\n",
       "       [0.2863674 , 0.38676265, 0.3390848 ],\n",
       "       [0.23038538, 0.50465006, 0.26334178],\n",
       "       [0.23727456, 0.5191926 , 0.24937671],\n",
       "       [0.27823967, 0.53324944, 0.19105   ],\n",
       "       [0.26777753, 0.43704006, 0.29486278],\n",
       "       [0.32156244, 0.41852707, 0.24349624],\n",
       "       [0.26688507, 0.4403127 , 0.28196913],\n",
       "       [0.2540979 , 0.22601798, 0.54728806],\n",
       "       [0.26969367, 0.40658313, 0.29484674],\n",
       "       [0.22152121, 0.43367514, 0.3271316 ],\n",
       "       [0.3134584 , 0.1622369 , 0.6107076 ],\n",
       "       [0.2837016 , 0.5355313 , 0.18504375],\n",
       "       [0.2612705 , 0.1257434 , 0.72159994],\n",
       "       [0.361393  , 0.47910053, 0.15759304],\n",
       "       [0.24091229, 0.4035797 , 0.3433072 ],\n",
       "       [0.24871118, 0.49915108, 0.26209736],\n",
       "       [0.3199657 , 0.23586436, 0.4389717 ],\n",
       "       [0.246603  , 0.21096861, 0.5784653 ],\n",
       "       [0.2802906 , 0.43213558, 0.30932337],\n",
       "       [0.28194156, 0.5079269 , 0.20563965],\n",
       "       [0.21852808, 0.1991835 , 0.5843743 ],\n",
       "       [0.42494628, 0.36825427, 0.23296724],\n",
       "       [0.25547713, 0.4980154 , 0.23991714],\n",
       "       [0.28193852, 0.20927839, 0.544625  ],\n",
       "       [0.3341864 , 0.13319658, 0.6336297 ],\n",
       "       [0.26415995, 0.5107785 , 0.22348996],\n",
       "       [0.23396032, 0.25764635, 0.51343167],\n",
       "       [0.22468099, 0.35263643, 0.40590018],\n",
       "       [0.3455408 , 0.184921  , 0.51868945],\n",
       "       [0.27753156, 0.30750498, 0.44794416],\n",
       "       [0.25659406, 0.5032055 , 0.23714945],\n",
       "       [0.38080126, 0.19348252, 0.45842728],\n",
       "       [0.26073152, 0.35519966, 0.3443905 ],\n",
       "       [0.24834715, 0.5051306 , 0.2428199 ],\n",
       "       [0.2581238 , 0.46560642, 0.26654652],\n",
       "       [0.27407455, 0.5356031 , 0.19725582],\n",
       "       [0.2545601 , 0.53930473, 0.21040209],\n",
       "       [0.22186396, 0.28422588, 0.47606775],\n",
       "       [0.2489835 , 0.37917775, 0.3517333 ],\n",
       "       [0.2462712 , 0.32385853, 0.44671354],\n",
       "       [0.24364652, 0.43271118, 0.33129913],\n",
       "       [0.2662334 , 0.26938894, 0.4993633 ],\n",
       "       [0.35713828, 0.2894284 , 0.34177092],\n",
       "       [0.25175554, 0.31185317, 0.4082212 ],\n",
       "       [0.35600436, 0.3562505 , 0.2913172 ],\n",
       "       [0.31486768, 0.46065518, 0.20651156],\n",
       "       [0.2380816 , 0.47332454, 0.27892315],\n",
       "       [0.29302564, 0.26724073, 0.43536603],\n",
       "       [0.32620654, 0.5024472 , 0.17592853],\n",
       "       [0.21697833, 0.26051012, 0.50799114],\n",
       "       [0.25203136, 0.3249583 , 0.4178705 ],\n",
       "       [0.33004105, 0.24185702, 0.4487213 ],\n",
       "       [0.25837797, 0.35517052, 0.39804307]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621e6979-a1a0-4089-ab3f-361d85a9b529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

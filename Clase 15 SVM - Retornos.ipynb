{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "158bf6a1-1087-435d-b128-65e1266c11a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cierre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fecha</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11/20/2017</th>\n",
       "      <td>$67,88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11/27/2017</th>\n",
       "      <td>$69,68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/4/2017</th>\n",
       "      <td>$69,28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/11/2017</th>\n",
       "      <td>$68,72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/18/2017</th>\n",
       "      <td>$71,97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Cierre\n",
       "Fecha               \n",
       "11/20/2017   $67,88 \n",
       "11/27/2017   $69,68 \n",
       "12/4/2017    $69,28 \n",
       "12/11/2017   $68,72 \n",
       "12/18/2017   $71,97 "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/nparis87/MachineLearning/main/energy_etf.csv'\n",
    "\n",
    "precio = pd.read_csv(url, sep=\";\", index_col=0, decimal=',')\n",
    "precio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31d1290a-4f99-41c9-8acf-8934cd7f17df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-fbc510357ecc>:1: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  precio.Cierre = precio.Cierre.str.replace('$', '').str.replace(',', '.').astype(float)\n"
     ]
    }
   ],
   "source": [
    "precio.Cierre = precio.Cierre.str.replace('$', '').str.replace(',', '.').astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3985f3a-d225-4c9f-a799-f0417dcc6add",
   "metadata": {},
   "source": [
    "## Convertir el Ã­ndice en fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a77ed5e-1b12-4fe6-806f-a3316c6d654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "precio.index = pd.to_datetime(precio.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7e8104-745b-4038-88f7-799ef115e71f",
   "metadata": {},
   "source": [
    "## Obtener retornos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "921cdd34-d8aa-4aff-8110-197215d7a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retornos = precio.pct_change().dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cb0606-8eec-4b1f-9fda-ed28930c7f70",
   "metadata": {},
   "source": [
    "## Clasificar los resultados como una de tres clases: Retorno alcista +1, Retorno plano 0, Retorno bajista -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7b8f467-bfd6-47b9-bfb7-55917648eee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar(x):\n",
    "    if x > umbral:\n",
    "        y = 1\n",
    "    elif (x < umbral) and (x > -umbral):\n",
    "        y = 0\n",
    "    else:\n",
    "        y = -1\n",
    "    \n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ce1d51f-2cce-44c8-9729-374dec9a370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "umbral = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43efd446-45f4-4864-9286-fcb8e05e5baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "retornos['clase'] = retornos.Cierre.apply(clasificar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c26fde2-8707-4284-a70f-bc79470c9e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "retornos.head(10)\n",
    "mat_retornos = retornos.Cierre.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b72e95-92b6-4d56-a058-7f29524b28a9",
   "metadata": {},
   "source": [
    "## Construimos el set de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fae2b635-44c5-4f57-abf3-8f47a9a793e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "per = 15 # ventana de tiempo - Columnas\n",
    "muestras = 60\n",
    "\n",
    "variables = np.zeros((1,per))\n",
    "l = len(mat_retornos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "44d680b4-414a-43c7-9174-779765f672b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(muestras):\n",
    "    variables = np.concatenate((variables, mat_retornos[l-per-x: l-x].reshape((1,per))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c9048bed-4e81-43fc-91dc-bb969a5e7f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 15)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "de0abecd-036d-4340-854b-c56d7e62dd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = variables[1:]\n",
    "\n",
    "X = variables[:,:-1]\n",
    "Y = variables[:,-1]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a74f2-239f-4026-9a27-7ef71fe31a06",
   "metadata": {},
   "source": [
    "## Una manera interesante de modificar valores de matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d39f479b-7404-476a-b9b0-e72c98dba857",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral = [not x for x in ((Y>umbral)|(Y<-umbral))]\n",
    "\n",
    "Y[Y>umbral] = 1\n",
    "Y[Y<-umbral] = -1\n",
    "Y[neutral] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "87de6eef-e7f8-4996-9776-0b9ae4aca3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  1.,  1.,  1.,  0.,  1.,  1., -1., -1.,  0., -1.,  1.,\n",
       "        0.,  1., -1.,  1.,  1., -1., -1.,  0., -1., -1.,  0.,  0.,  1.,\n",
       "        0., -1.,  1.,  0., -1.,  0.,  1., -1.,  1., -1.,  1.,  1.,  0.,\n",
       "       -1.,  1.,  1.,  1., -1.,  1.,  1.,  0.,  0., -1.,  1.,  0.,  0.,\n",
       "       -1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7c5af0a2-5a85-4889-93c4-f1fe426f529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_entrenamiento = int(len(variables)*0.7)\n",
    "x_train = X[:i_entrenamiento, :]\n",
    "x_test =  X[i_entrenamiento:, :]\n",
    "y_train = Y[:i_entrenamiento]\n",
    "y_test =  Y[i_entrenamiento:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d651ec38-9664-4a75-9bd2-bef6b66cb226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 14)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "48abc839-e2f7-44e2-9d6a-845d412e3dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6b69da46-3d9c-4d39-9717-0e9435ac177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "72ff6e96-8981-405f-95ab-ac5c5245053a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test == pred).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b733a9a3-4e8e-4781-836a-b90b1df5b6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on SVC in module sklearn.svm._classes object:\n",
      "\n",
      "class SVC(sklearn.svm._base.BaseSVC)\n",
      " |  SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
      " |  \n",
      " |  C-Support Vector Classification.\n",
      " |  \n",
      " |  The implementation is based on libsvm. The fit time scales at least\n",
      " |  quadratically with the number of samples and may be impractical\n",
      " |  beyond tens of thousands of samples. For large datasets\n",
      " |  consider using :class:`~sklearn.svm.LinearSVC` or\n",
      " |  :class:`~sklearn.linear_model.SGDClassifier` instead, possibly after a\n",
      " |  :class:`~sklearn.kernel_approximation.Nystroem` transformer.\n",
      " |  \n",
      " |  The multiclass support is handled according to a one-vs-one scheme.\n",
      " |  \n",
      " |  For details on the precise mathematical formulation of the provided\n",
      " |  kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
      " |  other, see the corresponding section in the narrative documentation:\n",
      " |  :ref:`svm_kernels`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <svm_classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  C : float, default=1.0\n",
      " |      Regularization parameter. The strength of the regularization is\n",
      " |      inversely proportional to C. Must be strictly positive. The penalty\n",
      " |      is a squared l2 penalty.\n",
      " |  \n",
      " |  kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'}, default='rbf'\n",
      " |      Specifies the kernel type to be used in the algorithm.\n",
      " |      It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
      " |      a callable.\n",
      " |      If none is given, 'rbf' will be used. If a callable is given it is\n",
      " |      used to pre-compute the kernel matrix from data matrices; that matrix\n",
      " |      should be an array of shape ``(n_samples, n_samples)``.\n",
      " |  \n",
      " |  degree : int, default=3\n",
      " |      Degree of the polynomial kernel function ('poly').\n",
      " |      Ignored by all other kernels.\n",
      " |  \n",
      " |  gamma : {'scale', 'auto'} or float, default='scale'\n",
      " |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |      - if ``gamma='scale'`` (default) is passed then it uses\n",
      " |        1 / (n_features * X.var()) as value of gamma,\n",
      " |      - if 'auto', uses 1 / n_features.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``gamma`` changed from 'auto' to 'scale'.\n",
      " |  \n",
      " |  coef0 : float, default=0.0\n",
      " |      Independent term in kernel function.\n",
      " |      It is only significant in 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |  shrinking : bool, default=True\n",
      " |      Whether to use the shrinking heuristic.\n",
      " |      See the :ref:`User Guide <shrinking_svm>`.\n",
      " |  \n",
      " |  probability : bool, default=False\n",
      " |      Whether to enable probability estimates. This must be enabled prior\n",
      " |      to calling `fit`, will slow down that method as it internally uses\n",
      " |      5-fold cross-validation, and `predict_proba` may be inconsistent with\n",
      " |      `predict`. Read more in the :ref:`User Guide <scores_probabilities>`.\n",
      " |  \n",
      " |  tol : float, default=1e-3\n",
      " |      Tolerance for stopping criterion.\n",
      " |  \n",
      " |  cache_size : float, default=200\n",
      " |      Specify the size of the kernel cache (in MB).\n",
      " |  \n",
      " |  class_weight : dict or 'balanced', default=None\n",
      " |      Set the parameter C of class i to class_weight[i]*C for\n",
      " |      SVC. If not given, all classes are supposed to have\n",
      " |      weight one.\n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |  verbose : bool, default=False\n",
      " |      Enable verbose output. Note that this setting takes advantage of a\n",
      " |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      " |      properly in a multithreaded context.\n",
      " |  \n",
      " |  max_iter : int, default=-1\n",
      " |      Hard limit on iterations within solver, or -1 for no limit.\n",
      " |  \n",
      " |  decision_function_shape : {'ovo', 'ovr'}, default='ovr'\n",
      " |      Whether to return a one-vs-rest ('ovr') decision function of shape\n",
      " |      (n_samples, n_classes) as all other classifiers, or the original\n",
      " |      one-vs-one ('ovo') decision function of libsvm which has shape\n",
      " |      (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one\n",
      " |      ('ovo') is always used as multi-class strategy. The parameter is\n",
      " |      ignored for binary classification.\n",
      " |  \n",
      " |      .. versionchanged:: 0.19\n",
      " |          decision_function_shape is 'ovr' by default.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *decision_function_shape='ovr'* is recommended.\n",
      " |  \n",
      " |      .. versionchanged:: 0.17\n",
      " |         Deprecated *decision_function_shape='ovo' and None*.\n",
      " |  \n",
      " |  break_ties : bool, default=False\n",
      " |      If true, ``decision_function_shape='ovr'``, and number of classes > 2,\n",
      " |      :term:`predict` will break ties according to the confidence values of\n",
      " |      :term:`decision_function`; otherwise the first class among the tied\n",
      " |      classes is returned. Please note that breaking ties comes at a\n",
      " |      relatively high computational cost compared to a simple predict.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls the pseudo random number generation for shuffling the data for\n",
      " |      probability estimates. Ignored when `probability` is False.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  class_weight_ : ndarray of shape (n_classes,)\n",
      " |      Multipliers of parameter C for each class.\n",
      " |      Computed based on the ``class_weight`` parameter.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      The classes labels.\n",
      " |  \n",
      " |  coef_ : ndarray of shape (n_classes * (n_classes - 1) / 2, n_features)\n",
      " |      Weights assigned to the features (coefficients in the primal\n",
      " |      problem). This is only available in the case of a linear kernel.\n",
      " |  \n",
      " |      `coef_` is a readonly property derived from `dual_coef_` and\n",
      " |      `support_vectors_`.\n",
      " |  \n",
      " |  dual_coef_ : ndarray of shape (n_classes -1, n_SV)\n",
      " |      Dual coefficients of the support vector in the decision\n",
      " |      function (see :ref:`sgd_mathematical_formulation`), multiplied by\n",
      " |      their targets.\n",
      " |      For multiclass, coefficient for all 1-vs-1 classifiers.\n",
      " |      The layout of the coefficients in the multiclass case is somewhat\n",
      " |      non-trivial. See the :ref:`multi-class section of the User Guide\n",
      " |      <svm_multi_class>` for details.\n",
      " |  \n",
      " |  fit_status_ : int\n",
      " |      0 if correctly fitted, 1 otherwise (will raise warning)\n",
      " |  \n",
      " |  intercept_ : ndarray of shape (n_classes * (n_classes - 1) / 2,)\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  support_ : ndarray of shape (n_SV)\n",
      " |      Indices of support vectors.\n",
      " |  \n",
      " |  support_vectors_ : ndarray of shape (n_SV, n_features)\n",
      " |      Support vectors.\n",
      " |  \n",
      " |  n_support_ : ndarray of shape (n_classes,), dtype=int32\n",
      " |      Number of support vectors for each class.\n",
      " |  \n",
      " |  probA_ : ndarray of shape (n_classes * (n_classes - 1) / 2)\n",
      " |  probB_ : ndarray of shape (n_classes * (n_classes - 1) / 2)\n",
      " |      If `probability=True`, it corresponds to the parameters learned in\n",
      " |      Platt scaling to produce probability estimates from decision values.\n",
      " |      If `probability=False`, it's an empty array. Platt scaling uses the\n",
      " |      logistic function\n",
      " |      ``1 / (1 + exp(decision_value * probA_ + probB_))``\n",
      " |      where ``probA_`` and ``probB_`` are learned from the dataset [2]_. For\n",
      " |      more information on the multiclass case and training procedure see\n",
      " |      section 8 of [1]_.\n",
      " |  \n",
      " |  shape_fit_ : tuple of int of shape (n_dimensions_of_X,)\n",
      " |      Array dimensions of training vector ``X``.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.pipeline import make_pipeline\n",
      " |  >>> from sklearn.preprocessing import StandardScaler\n",
      " |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
      " |  >>> y = np.array([1, 1, 2, 2])\n",
      " |  >>> from sklearn.svm import SVC\n",
      " |  >>> clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
      " |  >>> clf.fit(X, y)\n",
      " |  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      " |                  ('svc', SVC(gamma='auto'))])\n",
      " |  \n",
      " |  >>> print(clf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  SVR : Support Vector Machine for Regression implemented using libsvm.\n",
      " |  \n",
      " |  LinearSVC : Scalable Linear Support Vector Machine for classification\n",
      " |      implemented using liblinear. Check the See Also section of\n",
      " |      LinearSVC for more comparison element.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] `LIBSVM: A Library for Support Vector Machines\n",
      " |      <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`_\n",
      " |  \n",
      " |  .. [2] `Platt, John (1999). \"Probabilistic outputs for support vector\n",
      " |      machines and comparison to regularizedlikelihood methods.\"\n",
      " |      <http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.1639>`_\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SVC\n",
      " |      sklearn.svm._base.BaseSVC\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.svm._base.BaseLibSVM\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Evaluates the decision function for the samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : ndarray of shape (n_samples, n_classes * (n_classes-1) / 2)\n",
      " |          Returns the decision function of the sample for each class\n",
      " |          in the model.\n",
      " |          If decision_function_shape='ovr', the shape is (n_samples,\n",
      " |          n_classes).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If decision_function_shape='ovo', the function values are proportional\n",
      " |      to the distance of the samples X to the separating hyperplane. If the\n",
      " |      exact distances are required, divide the function values by the norm of\n",
      " |      the weight vector (``coef_``). See also `this question\n",
      " |      <https://stats.stackexchange.com/questions/14876/\n",
      " |      interpreting-distance-from-hyperplane-in-svm>`_ for further details.\n",
      " |      If decision_function_shape='ovr', the decision function is a monotonic\n",
      " |      transformation of ovo decision function.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform classification on samples in X.\n",
      " |      \n",
      " |      For an one-class model, +1 or -1 is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features) or                 (n_samples_test, n_samples_train)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,)\n",
      " |          Class labels for samples in X.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  predict_log_proba\n",
      " |      Compute log probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features) or                 (n_samples_test, n_samples_train)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : ndarray of shape (n_samples, n_classes)\n",
      " |          Returns the log-probabilities of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  predict_proba\n",
      " |      Compute probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : ndarray of shape (n_samples, n_classes)\n",
      " |          Returns the probability of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  probA_\n",
      " |  \n",
      " |  probB_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the SVM model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)                 or (n_samples, n_samples)\n",
      " |          Training vectors, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples, n_samples).\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Per-sample weights. Rescale C per sample. Higher weights\n",
      " |          force the classifier to put more emphasis on these points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      " |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      " |      \n",
      " |      If X is a dense array, then the other methods will not support sparse\n",
      " |      matrices as input.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  coef_\n",
      " |  \n",
      " |  n_support_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef869e26-2118-446c-83a4-8e7f30957559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost in Python, From Start to Finish (Credit Default)\n",
    "\n",
    "----\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # load and manipulate data and for One-Hot Encoding\n",
    "import numpy as np # calculate the mean and standard deviation\n",
    "import xgboost as xgb # XGBoost stuff\n",
    "from sklearn.model_selection import train_test_split # split  data into training and testing sets\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer # for scoring during cross validation\n",
    "from sklearn.model_selection import GridSearchCV # cross validation\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, classification_report # creates and draws a confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"download-the-data\"></a>\n",
    "# Import the data\n",
    "Now we load in a dataset from the **[UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)**.\n",
    "Specifically, we are going to use the **[Credit Card Default](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)** dataset. This dataset will allow us to predict if someone will default on their credit card payments based on their sex, age and a variety of other metrics.\n",
    "\n",
    "**NOTE:** When **pandas** (**pd**) reads in data, it returns a **data frame**, which is a lot like a spreadsheet. The data are organized in rows and columns and each row can contain a mixture of text and numbers. The standard variable name for a **data frame** is the initials **df**, and that is what we will use here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'https://raw.githubusercontent.com/nparis87/MachineLearning/main/CreditQuality.csv'\n",
    "\n",
    "data = pd.read_csv(source, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded the data into a **data frame** called **df**, let's look at the first five rows using the `head()` function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, the values in the **ID** column were randomly assigned, making it uninformative, so we can drop it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "      <th>Column4</th>\n",
       "      <th>Column5</th>\n",
       "      <th>Column6</th>\n",
       "      <th>Column7</th>\n",
       "      <th>Column8</th>\n",
       "      <th>Column9</th>\n",
       "      <th>Column10</th>\n",
       "      <th>...</th>\n",
       "      <th>Column12</th>\n",
       "      <th>Column13</th>\n",
       "      <th>Column14</th>\n",
       "      <th>Column15</th>\n",
       "      <th>Column16</th>\n",
       "      <th>Column17</th>\n",
       "      <th>Column18</th>\n",
       "      <th>Column19</th>\n",
       "      <th>Column20</th>\n",
       "      <th>Column21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>43</td>\n",
       "      <td>1169</td>\n",
       "      <td>65</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "      <td>93</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>67</td>\n",
       "      <td>143</td>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>32</td>\n",
       "      <td>43</td>\n",
       "      <td>5951</td>\n",
       "      <td>61</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>22</td>\n",
       "      <td>143</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>191</td>\n",
       "      <td>201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>46</td>\n",
       "      <td>2096</td>\n",
       "      <td>61</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>49</td>\n",
       "      <td>143</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>2</td>\n",
       "      <td>191</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>7882</td>\n",
       "      <td>61</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>45</td>\n",
       "      <td>143</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>2</td>\n",
       "      <td>191</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>4870</td>\n",
       "      <td>61</td>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>124</td>\n",
       "      <td>53</td>\n",
       "      <td>143</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>2</td>\n",
       "      <td>191</td>\n",
       "      <td>201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column1  Column2  Column3  Column4  Column5  Column6  Column7  Column8  \\\n",
       "0       11        6       34       43     1169       65       75        4   \n",
       "1       12       48       32       43     5951       61       73        2   \n",
       "2       14       12       34       46     2096       61       74        2   \n",
       "3       11       42       32       42     7882       61       74        2   \n",
       "4       11       24       33       40     4870       61       73        3   \n",
       "\n",
       "   Column9  Column10  ...  Column12  Column13  Column14  Column15  Column16  \\\n",
       "0       93       101  ...       121        67       143       152         2   \n",
       "1       92       101  ...       121        22       143       152         1   \n",
       "2       93       101  ...       121        49       143       152         1   \n",
       "3       93       103  ...       122        45       143       153         1   \n",
       "4       93       101  ...       124        53       143       153         2   \n",
       "\n",
       "   Column17  Column18  Column19  Column20  Column21  \n",
       "0       173         1       192       201         0  \n",
       "1       173         1       191       201         1  \n",
       "2       172         2       191       201         0  \n",
       "3       173         2       191       201         0  \n",
       "4       173         2       191       201         1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.drop('ID', axis=1, inplace=True) ## set axis=0 to remove rows, axis=1 to remove columns\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Data: Dealing With Missing Data, XGBoost Style\n",
    "\n",
    "One thing that is relatively unique about **XGBoost** is that it determines default behavior for missing data. So all we have to do is identify missing values and make sure they are set to `0`.\n",
    "\n",
    "However, before we do that, let's see how many rows are missing data. If it's a lot, then we might have a problem on our hands that is bigger than what **XGBoost** can deal with on its own. If it's not that many, we can just set them to `0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "      <th>Column4</th>\n",
       "      <th>Column5</th>\n",
       "      <th>Column6</th>\n",
       "      <th>Column7</th>\n",
       "      <th>Column8</th>\n",
       "      <th>Column9</th>\n",
       "      <th>Column10</th>\n",
       "      <th>Column11</th>\n",
       "      <th>Column12</th>\n",
       "      <th>Column13</th>\n",
       "      <th>Column14</th>\n",
       "      <th>Column15</th>\n",
       "      <th>Column16</th>\n",
       "      <th>Column17</th>\n",
       "      <th>Column18</th>\n",
       "      <th>Column19</th>\n",
       "      <th>Column20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>43</td>\n",
       "      <td>1169</td>\n",
       "      <td>65</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "      <td>93</td>\n",
       "      <td>101</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>67</td>\n",
       "      <td>143</td>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>32</td>\n",
       "      <td>43</td>\n",
       "      <td>5951</td>\n",
       "      <td>61</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>22</td>\n",
       "      <td>143</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>191</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>46</td>\n",
       "      <td>2096</td>\n",
       "      <td>61</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "      <td>121</td>\n",
       "      <td>49</td>\n",
       "      <td>143</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>2</td>\n",
       "      <td>191</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>7882</td>\n",
       "      <td>61</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>122</td>\n",
       "      <td>45</td>\n",
       "      <td>143</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>2</td>\n",
       "      <td>191</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>4870</td>\n",
       "      <td>61</td>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "      <td>101</td>\n",
       "      <td>4</td>\n",
       "      <td>124</td>\n",
       "      <td>53</td>\n",
       "      <td>143</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>2</td>\n",
       "      <td>191</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column1  Column2  Column3  Column4  Column5  Column6  Column7  Column8  \\\n",
       "0       11        6       34       43     1169       65       75        4   \n",
       "1       12       48       32       43     5951       61       73        2   \n",
       "2       14       12       34       46     2096       61       74        2   \n",
       "3       11       42       32       42     7882       61       74        2   \n",
       "4       11       24       33       40     4870       61       73        3   \n",
       "\n",
       "   Column9  Column10  Column11  Column12  Column13  Column14  Column15  \\\n",
       "0       93       101         4       121        67       143       152   \n",
       "1       92       101         2       121        22       143       152   \n",
       "2       93       101         3       121        49       143       152   \n",
       "3       93       103         4       122        45       143       153   \n",
       "4       93       101         4       124        53       143       153   \n",
       "\n",
       "   Column16  Column17  Column18  Column19  Column20  \n",
       "0         2       173         1       192       201  \n",
       "1         1       173         1       191       201  \n",
       "2         1       172         2       191       201  \n",
       "3         1       173         2       191       201  \n",
       "4         2       173         2       191       201  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop('Column21', axis=1).copy() # alternatively: X = df_no_missing.iloc[:,:-1]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "Name: Column21, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['Column21'].copy()\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created **X**, which has the data we want to use to make predictions, and **y**, which has the data we want to predict, we are ready to continue formatting **X** so that it is suitable for making a model with **XGBoost**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"one-hot-encoding\"></a>\n",
    "# Format the Data Part 2: One-Hot Encoding\n",
    "\n",
    "Now that we have split the data frame into two pieces, `X`, which contains the data we will use to make, or predict, classifications, and `y`, which contains the known classifications in our training dataset, we need to take a closer look at the variables in `X`. The list below tells us what each variable represents and the type of data (**float** or **categorical**) it should contain:\n",
    "\n",
    "- **LIMIT_BAL**, The amount of available credit **Integer**\n",
    "- **SEX**, **Category**\n",
    "  - 1 = male\n",
    "  - 2 = female\n",
    "- **EDUCATION**, **Category**\n",
    "  - 1 = graduate school\n",
    "  - 2 = university\n",
    "  - 3 = high school\n",
    "  - 4 = others\n",
    "- **MARRIAGE**, **Category**\n",
    "  - 1 = Married\n",
    "  - 2 = Single\n",
    "  - 3 = Other\n",
    "- **AGE**, **Integer**\n",
    "- **PAY_**, When the last 6 bills were payed **Category**\n",
    "  - -1 = Paid on time\n",
    "  - 1 = Payment delayed by 1 month\n",
    "  - 2 = Payment delayed by 2 months\n",
    "  - ...\n",
    "  - 8 = Payment delayed by 8 months\n",
    "  - 9 = Payment delayed by 9 or more months\n",
    "- **BILL_AMT**, What the last 6 bills were **Integer**\n",
    "- **PAY_AMT**, How much the last payments were **Integer**\n",
    "- **DEFAULT**, Whether or not a person defaulted on the next payment **CATEGORY**\n",
    "  - 0 = Did not default\n",
    "  - 1 = Defaulted\n",
    "  \n",
    "Now, just to review, let's look at the data types in `X` to remember how python is seeing the data right now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"build-tree\"></a>\n",
    "# Build A Preliminary XGBoost Model\n",
    "At long last, the data is correctly formatted for making an **XGBoost** model. Now we simply split the data into **training** and **testing** sets and build the model. However, first, let's observe that this data is imbalanced by dividing the number of people who defaulted, where `y = 1`, by the total number of people in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y)/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that only 22% of the people in the dataset defaulted. Because of this, when we split the data into training and testing, we will split using stratification in order to maintain the same percentage of people who defaulted in both the **training** set and the **testing** set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's verify that using `stratify` worked as expected..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train)/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                            seed=42)\n",
    "clf_xgb.fit(X_train, y_train)\n",
    "y_pred = clf_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, we've built an **XGBoost** model for classification. Let's see how it performs on the **Testing Dataset** by running the **Testing Dataset** down the model and drawing a **Confusion Matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x24ff7e99c10>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Did not default\", \"Defaulted\"])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the confusion matrix, we see that of the **5841** people that did not default, **5491 (94%)** were correctly classified. So that's good. However, of the **1659** people that defaulted, only **619 (37%)** were correctly classified. So the **XGBoost** model was not awesome. Part of the problem is that our data is imbalanced, which we saw earlier and we see this in the confusion matrix with the top row showing **5841** people that did not default and the bottom row showing **1659** people who did. Because defaulting on loans costs the company a lot of money, we would like to capture more of the people that defaulted. The good news is that **XGBoost** has a parameter that helps with imbalanced data, So let's try to improve predictions using **Cross Validation** to optimize the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Did not default       0.83      0.88      0.85       175\n",
      "      Defaulted       0.67      0.57      0.62        75\n",
      "\n",
      "       accuracy                           0.79       250\n",
      "      macro avg       0.75      0.73      0.74       250\n",
      "   weighted avg       0.78      0.79      0.78       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred,target_names=[\"Did not default\", \"Defaulted\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, after testing all possible combinations of the potential parameter values with **Cross Validation**, we see that we should set `gamma=0`, `learning_rate=0.1`, `max_depth=6`, `reg_lambda=500` and `scale_pos_weight=3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"draw-tree\"></a>\n",
    "# Building, Evaluating, Drawing, and Interpreting the Optimized XGBoost Model\n",
    "\n",
    "Now that we have the ideal parameter values, we can build the final **XGBoost** model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = xgb.XGBClassifier(seed=42,\n",
    "                            objective='binary:logistic',\n",
    "                            gamma=0,\n",
    "                            learning_rate=0.1,\n",
    "                            max_depth=6,\n",
    "                            reg_lambda=500,\n",
    "                            scale_pos_weight=3,\n",
    "                            subsample=0.9,\n",
    "                            colsample_bytree=0.5,\n",
    "                            ## the next two arguments set up early stopping:\n",
    "                            eval_metric='aucpr',\n",
    "                            early_stopping_rounds=10)\n",
    "                        \n",
    "clf_xgb.fit(X_train, \n",
    "            y_train, \n",
    "            verbose=True, \n",
    "            eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's draw another confusion matrix to see if the optimized **XGBoost** model does better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(clf_xgb,\n",
    "                                      X_test,\n",
    "                                      y_test,\n",
    "                                      values_format='d',\n",
    "                                      display_labels=[\"Did not default\", \"Defaulted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the optimized **XGBoost** model is now almost twice as good at correctly classifying people that defaulted. This was at the expense of incorrectly classifying people that did not default, and this tradeoff is something that the company might have to think about. However, from our perspective, this was a success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we are going to do is draw the first **XGBoost Tree** and discuss how to interpret it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If we want to get information, like gain and cover etc, at each node in the first tree, \n",
    "## we just build the first tree, otherwise we'll get the average over all of the trees.\n",
    "clf_xgb = xgb.XGBClassifier(seed=42,\n",
    "                            objective='binary:logistic',\n",
    "                            gamma=0,\n",
    "                            learning_rate=0.1,\n",
    "                            max_depth=6,\n",
    "                            reg_lambda=500,\n",
    "                            scale_pos_weight=3,\n",
    "                            subsample=0.9,\n",
    "                            colsample_bytree=0.5,\n",
    "                            n_estimators=1, ## We set this to 1 so we can get gain, cover etc.\n",
    "                            )\n",
    "clf_xgb.fit(X_train, y_train)\n",
    "\n",
    "## now print out the weight, gain, cover etc. for the tree\n",
    "## weight = number of times a feature is used in a branch or root across all trees\n",
    "## gain = the average gain across all splits that the feature is used in\n",
    "## cover = the average coverage across all splits a feature is used in\n",
    "## total_gain = the total gain across all splits the feature is used in\n",
    "## total_cover = the total coverage across all splits the feature is used in\n",
    "## NOTE: Since we only built one tree, gain = total_gain and cover=total_cover\n",
    "bst = clf_xgb.get_booster()\n",
    "for importance_type in ('weight', 'gain', 'cover', 'total_gain', 'total_cover'):\n",
    "    print('%s: ' % importance_type, bst.get_score(importance_type=importance_type))\n",
    "\n",
    "node_params = {'shape': 'box', ## make the nodes fancy\n",
    "               'style': 'filled, rounded',\n",
    "               'fillcolor': '#78cbe'} \n",
    "leaf_params = {'shape': 'box',\n",
    "               'style': 'filled',\n",
    "               'fillcolor': '#e48038'}\n",
    "## NOTE: num_trees is NOT the number of trees to plot, but the specific tree you want to plot\n",
    "## The default value is 0, but I'm setting it just to show it in action since it is\n",
    "## counter-intuitive.\n",
    "xgb.to_graphviz(clf_xgb, num_trees=0, \n",
    "                condition_node_params=node_params,\n",
    "                leaf_node_params=leaf_params)\n",
    "## if you want to save the figure...\n",
    "# graph_data = xgb.to_graphviz(clf_xgb, num_trees=0, size=\"10,10\", \n",
    "#                 condition_node_params=node_params,\n",
    "#                 leaf_node_params=leaf_params) \n",
    "# graph_data.view(filename='xgboost_tree_credit_card') ## save as PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's discuss how to interpret the **XGBoost Tree**.\n",
    "In each node, we have:\n",
    "- The variable (column name) and the threshold for splitting the observations. For example, in the tree's root, we use **PAY_2_2** to split the observations. All observations with **PAY_2_2 < 0.5** go to the **left** and all observations with **PAY_2_2 =< 0.5** go to the **right**.\n",
    "- Each branch either says **yes** or **no** and some also say **missing**. \n",
    " - **yes** and **no** refer to whether the threshold in the node above it is true or not. If so, then **yes**, if not, then **no**. \n",
    " - **missing** is the default option if there is missing data.\n",
    "- **leaf** tells us the output value for each leaf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In conclusion we...\n",
    "\n",
    "- **[Loaded the Data From a File](#download-the-data)**\n",
    "\n",
    "- **[Identified and Dealt with Missing Data](#identify-and-deal-with-missing-data)**\n",
    "\n",
    "- **[Formatted the Data for XGBoost using One-Hot Encoding](#one-hot-encoding)**\n",
    "\n",
    "- **[Built an XGBoost Model for Classification](#build-tree)**\n",
    "\n",
    "- **[Optimize the XGBoost Parameters with Cross Validation and GridSearch()](#prune-tree)**\n",
    "\n",
    "- **[Built, Drew, Interpreted and Evaluated the Optimized XGBoost Model](#draw-tree)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRIPLE BAM!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

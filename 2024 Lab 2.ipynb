{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff1604d2-e541-4890-bd19-3c8cd202b9de",
   "metadata": {},
   "source": [
    "## Laboratorio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b99d80-09eb-4a87-babe-558da11885b6",
   "metadata": {},
   "source": [
    "### Based on the information provided, the investment strategy area wishes to develop a model that gives weekly purchase signals that result in high levels of effectiveness.\n",
    "\n",
    "1. Evaluate the classification model that gives the best buying signals to investors in the ETF whose price you find in the database. Apply Gridsearch with cross validation for each model in just one function. Below you will find a pre-started function for your reference that you can complement and modify as you consider needed. \n",
    "    \n",
    "    a. Analyze the ranking behavior of the models included in the lists provided.\n",
    "\n",
    "    b. In the evaluation include testing various parameters such as changing the number of weeks of lag in returns, and changing any of the model parameters. For example, number of neighbors in KNN,        calculation of the number of levels in a classification tree, number of trees in a random forest, among others. Among          all tests you must evaluate at least 6 combinations of parameters/models. An example of combinations would be:\n",
    "\n",
    "        i.      KNN, 5 neighbors, using prices with 10 week timeframe\n",
    "        \n",
    "\n",
    "2. If your goal is to make investment decisions for next week, choose a model and justify why. Ultimately, the model you should choose is the one with the highest percentage of success in making investment decisions. Remember that if the accuracy of classification 1 is 50% it means that half of the buy signals are false and half are correct. If the recall is 50%, it means that the model will identify half of the good purchasing opportunities and will make us lose the other half. Remember to play with the time window and threshold.\n",
    "\n",
    "       a. Analyze and justify your choice\n",
    "       b. This exercise was done with the XLI, an industrials stocks ETF. If we change the data set to the XLK, of technology           stocks, would the model still have the same good results? Convert data with XLK to x_test and y_test test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ac834f-4b8b-4c34-8195-20d2a5b9f21a",
   "metadata": {},
   "source": [
    "### Deliver this lab in PDF or HTML format.\n",
    "Make sure the delivered file can be opened fine. In the case of HTML files, try opening it in a browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422b1c36-ec88-499e-bbd3-353dd0123241",
   "metadata": {},
   "source": [
    "## Some helpful code is provided bellow. It can serve to load data and organice functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9067fed3-8860-4d18-86ee-950fb10c2045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install yfinance\n",
    "import yfinance as yf\n",
    "precios = yf.Ticker('XLI').history(period=\"10y\", interval='1wk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "158bf6a1-1087-435d-b128-65e1266c11a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8268bed-d2ed-42eb-9262-abb2d9e39c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "precios = precios.Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e105698-53b8-4210-9606-964d2205a3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2013-11-25    41.729191\n",
       "2013-12-02    41.679508\n",
       "2013-12-09    41.207561\n",
       "2013-12-16    42.441219\n",
       "2013-12-20          NaN\n",
       "2013-12-23    43.273209\n",
       "2013-12-30    42.998577\n",
       "2014-01-06    43.214958\n",
       "2014-01-13    43.123417\n",
       "2014-01-20    41.450752\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precios.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7e18e9b-d55a-4ac4-a629-606c335124c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "retornos = np.log(precios).diff()[1:].dropna()\n",
    "mat_retornos = retornos.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "065848b0-76ed-499b-9cfe-574cbda7795a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_retornos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28e1b9e-83f3-42cc-88ec-d63e4abfe3c6",
   "metadata": {},
   "source": [
    "## This is an example of how a list of models can be put together to run secuentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0d87f1-b927-4788-81e6-af555ef00ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Nearest Neighbors\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"AdaBoost\",\n",
    "    \"XGBoost\"]\n",
    "\n",
    "classifiers = [KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=50, max_features=1),\n",
    "    AdaBoostClassifier()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edefdac5-7b95-4ef3-b700-9ccec2c3b615",
   "metadata": {},
   "source": [
    "## This is a function to run the model, adapt the function so that it evaluates all models included in the list above. Make sure you import the libraries corresponding to all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c2ac32a-ba0e-43c1-8858-5086c1daec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prueba_modelo(per, umbral, h):        \n",
    "        \n",
    "        # ventana de tiempo - Columnas\n",
    "        muestras = len(mat_retornos) - per\n",
    "\n",
    "        variables = np.zeros((1,per))\n",
    "        l = len(mat_retornos)\n",
    "\n",
    "        for x in range(muestras):\n",
    "            variables = np.concatenate((variables, mat_retornos[l-per-x: l-x].reshape((1,per))))\n",
    "\n",
    "        variables = variables[1:]\n",
    "\n",
    "        X = variables[:,:-1]\n",
    "        Y = variables[:,-1]*100\n",
    "\n",
    "        # los retornos porcentuales en una semana determinada los vamos a clasificar como \"bajo, neutral o alto\"\n",
    "        # esto dependiendo del umbral que inicialmente vamos a establecerlo en 2%\n",
    "            \n",
    "        neutral = [not x for x in ((Y>umbral)|(Y<-umbral))]\n",
    "        \n",
    "        # Aquí vamos a modificar Y para clasificar los retornos -1 = bajo, 0 = neutral y 1 = alto\n",
    "        # La idea es que el modelo logre clasificar efectivamente los retornos altos.\n",
    "        \n",
    "        Y[Y>umbral] = 1\n",
    "        Y[Y<-umbral] = -1\n",
    "        Y[neutral] = 0\n",
    "\n",
    "        i_entrenamiento = int(len(variables)*0.7) #la fila hasta donde va el entrenamiento y donde comienza el conjunto de prueba\n",
    "        \n",
    "        # fíjese que el entrenamiento se hará utilizando datos hasta una fecha X, de ahí en adelante, probaremos el modelo\n",
    "        # hacia adelante en el tiempo con lo que será el conjunto de prueba\n",
    "        \n",
    "        x_train = X[:i_entrenamiento, :]\n",
    "        x_test =  X[i_entrenamiento:, :]\n",
    "        y_train = Y[:i_entrenamiento]\n",
    "        y_test =  Y[i_entrenamiento:]\n",
    "\n",
    "        modelo = SVC(C=1, kernel='rbf', gamma=1).fit(x_train, y_train)\n",
    "\n",
    "        pred = modelo.predict(x_test)\n",
    "    \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5fefc5-b257-4ae9-b53e-9285432b0200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621e6979-a1a0-4089-ab3f-361d85a9b529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
